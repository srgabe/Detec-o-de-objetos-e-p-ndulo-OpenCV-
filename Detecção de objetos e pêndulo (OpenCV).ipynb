{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6ccebf",
   "metadata": {},
   "source": [
    "### Parte 1) Filtro pelo pacote OpenCV para operações avançadas: (i) detectar contornos; (ii) detectar objeto; (iii) detectar padrões (rosto) em tempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441cde0f",
   "metadata": {},
   "source": [
    "i) Detectar contornos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbcb655e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando o pacote OpenCV (depois de instalá-lo)\n",
    "import cv2\n",
    "\n",
    "#Ler uma imagem e mostrá-la\n",
    "gatim = cv2.imread('gatim.jfif', cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Gatinho\", gatim)\n",
    "\n",
    "#Transformar a imagem em preto e branco (apesar dela já ser)\n",
    "gatimcinza = cv2.cvtColor(gatim, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gatinho preto e branco\", gatimcinza)\n",
    "\n",
    "# Imagem com os contornos destacados (canny = filtro com um Sobel kernel)\n",
    "canny = cv2.Canny(gatimcinza, 125, 175)\n",
    "cv2.imshow('Contornos do gatinho', canny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a572481",
   "metadata": {},
   "source": [
    "ii) Detectar objetos\n",
    "\n",
    "Neste código iremos utilizar o pacote openCV junto com um banco de dados (COCO dataset) de objetos, no intuito de detectar objetos semelhantes ao que possuem no banco de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f255a82",
   "metadata": {},
   "source": [
    "Exemplo 1: Detectar um carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89511e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # Importar pacote openCV\n",
    "\n",
    "img = cv2.imread('carro.PNG')\n",
    "\n",
    "# Crinado um array para colocar os nomes dos objetos\n",
    "classNames= []\n",
    "classFile = 'coco.names' #Importando a pasta dos nomes dos objetos\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Importando as outras pastas dos bancos de dados (COCO dataset)\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "# Criar um modelo de detecção a partir de uma network de deep learning\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "classIds, confs, bbox = net.detect(img, confThreshold=0.5)# Detecta arrays iguais do modelo \n",
    "#ClassIds=numero de identificação do objeto  #confthreshold=limite para detectar objeto\n",
    "\n",
    "#Caso encontre o contorno, marca e coloca o nome\n",
    "for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):\n",
    "    cv2.rectangle(img, box, color=(0, 255,0), thickness=2)\n",
    "    cv2.putText(img, classNames[classId-1], (box[0]+10, box[1]+30), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "cv2.imshow(\"Saida\", img) # Mostra a imagem\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0022a",
   "metadata": {},
   "source": [
    "Exemplo 2: Detectar gato e carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75548a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # Importar pacote openCV\n",
    "\n",
    "img = cv2.imread('cars-and-cats.jpg')\n",
    "\n",
    "# Crinado um array para colocar os nomes dos objetos\n",
    "classNames= []\n",
    "classFile = 'coco.names' #Importando a pasta dos nomes dos objetos\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Importando as outras pastas dos bancos de dados (COCO dataset)\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "# Criar um modelo de detecção a partir de uma network de deep learning\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "classIds, confs, bbox = net.detect(img, confThreshold=0.5)# Detecta arrays iguais do modelo \n",
    "#ClassIds=numero de identificação do objeto  #confthreshold=limite para detectar objeto\n",
    "\n",
    "#Caso encontre o contorno, marca e coloca o nome\n",
    "for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):\n",
    "    cv2.rectangle(img, box, color=(0, 255,0), thickness=2)\n",
    "    cv2.putText(img, classNames[classId-1], (box[0]+10, box[1]+30), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "cv2.imshow(\"Saida\", img) # Mostra a imagem\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b3e7e",
   "metadata": {},
   "source": [
    "iii) detectar padrões (rosto) em tempo real.\n",
    "\n",
    "Agora iremos executar este mesmo códico para reconhecer objetos e rostos em tempo real através da webcam. Como será utilizado um vídeo, temos que adicionar um loop com o while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f72e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Importar pacote openCV\n",
    "\n",
    "cap = cv2.VideoCapture(0) # Capturar video da webcam\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "cap.set(10,70)\n",
    "\n",
    "# Crinado um array para colocar os nomes dos objetos\n",
    "classNames= []\n",
    "classFile = 'coco.names' #Importando a pasta dos nomes dos objetos\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "# Importando as outras pastas dos bancos de dados (COCO dataset)\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "# Criar um modelo de detecção a partir de uma network de deep learning\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "# Loop para gerar o video\n",
    "while True:\n",
    "    success,img = cap.read() # Lê o video e separa as imagens em img (success mostra um true)\n",
    "    classIds, confs, bbox = net.detect(img,confThreshold=0.5) # Detecta arrays iguais do modelo \n",
    "    #ClassIds=numero de identificação do objeto  #confthreshold=limite para detectar objeto\n",
    "    if len(classIds) != 0: #Caso encontre o contorno, marca e coloca o nome\n",
    "        for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "            cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "            cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Captura de webcam',img) # Mostrar video\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break #Para quebrar o loop quando apertar o botão 'q'\n",
    "    if cv2.getWindowProperty('Captura de webcam', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break #Para quebrar o loop quando fechar a janela\n",
    "\n",
    "# Depois de quebrar o loop, fecha a webcam e fecha todas as janelas abertas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89db32",
   "metadata": {},
   "source": [
    "### Parte 2) OpenCV para rastrear o movimento de um objeto colorido: pêndulo com barbante pendurando um objeto colorido e capture o movimento como função do tempo do vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bd8a8",
   "metadata": {},
   "source": [
    "Nesta etapa iremos utilizar o pacote openCV para rastrear o movimento de um pêndulo, para isso iremos obter o contorno de objetos em movimento e distinguir quando o objeto está parado (ou seja quando ele está no ponto mais alto), para assim obter o periodo de oscilação e com isso poder obter a acerelação gravitacional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554d5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medido em 9 periodos. T medio: 0.72, T min: 0.2, T max: 1.83\n",
      "g medio: 11.41, g min: 1.77, g max: 147.89\n"
     ]
    }
   ],
   "source": [
    "# Importanto as bilbiotecas  \n",
    "from typing import Tuple\n",
    "import cv2\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "length = 0.15 # Comprimento da corda\n",
    "\n",
    "capture = cv2.VideoCapture(\"testependulo2.mp4\") # Puxa o vídeo dos arquivos\n",
    "fps = round(capture.get(cv2.CAP_PROP_FPS), 2) # Encontra e arredonda o frame rate (fps)\n",
    "\n",
    "# Obtendos os frames do video em duas matrizes \n",
    "_, frame1 = capture.read()\n",
    "_, frame2 = capture.read()\n",
    "\n",
    "time_start = time.time() # Define o tempo inicial\n",
    "# Definindo alguns arrays que serão utilizados mais adiante\n",
    "labels = []\n",
    "stops_list = []\n",
    "T_list = []\n",
    "T_half_list = []\n",
    "T_timestamps = []\n",
    "\n",
    "# Função para calcular o tempo (retorna um tuple de 3 elementos)\n",
    "def calc_T() -> Tuple[float, float, float]:\n",
    "    avg = round(numpy.mean(T_list), 2) #Periodo médio (avg=average)\n",
    "    low = round(numpy.min(T_list), 2) #Periodo mínimo\n",
    "    high = round(numpy.max(T_list), 2) #Periodo máximo\n",
    "    return (avg, low, high)\n",
    "\n",
    "# Função para calcular a aceleração gravitacional (retorna um tuple de 3 elementos)\n",
    "def calc_g() -> Tuple[float, float, float]:\n",
    "    T_avg, T_min, T_max = calc_T()\n",
    "    # Considerando pequenas oscilações (seno de teta = teta)\n",
    "    g_avg = (4 * 3.14 * 3.14 * length) / (T_avg**2) #g médio (avg=average)\n",
    "    g_min = (4 * 3.14 * 3.14 * length) / (T_max**2) #g mínimo\n",
    "    g_max = (4 * 3.14 * 3.14 * length) / (T_min**2) #g máximo\n",
    "    return (round(g_avg, 2), round(g_min, 2), round(g_max, 2))\n",
    "\n",
    "# Função para colocar texto no video\n",
    "def drawText(text: str, color: Tuple[int, int, int], pos: Tuple[int, int], big=False, console=False):\n",
    "    if console:\n",
    "        print(text)\n",
    "    if big:\n",
    "        scale = 1\n",
    "        thickness = 4\n",
    "    else:\n",
    "        scale = 0.6\n",
    "        thickness = 2\n",
    "\n",
    "    cv2.putText(frame1, str(text), org=pos, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=scale, color=color, thickness=3)\n",
    "\n",
    "\n",
    "prev_moving = False # Como não há movimento antes de tudo, deve ser false\n",
    "stops_count = 0 # Quantidades de vezes que o movimento para\n",
    "\n",
    "\n",
    "#Começar o loop para o video\n",
    "while capture.isOpened() and frame1 is not None and frame2 is not None:\n",
    "    t0 = cv2.getTickCount() # Retorna o número de ciclos de clock após um evento de referência\n",
    "    T = cv2.absdiff(frame1, frame2) # Calcula a diferença absoluta por elemento entre duas matrizes\n",
    "    gray = cv2.cvtColor(T, cv2.COLOR_BGR2GRAY) # Deixando a imagem preto e branco\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0) # Aplicando blur por gaussiana\n",
    "    _, threshold = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY) # Aplicando um limite (define melhor o contorno)\n",
    "    dilated = cv2.dilate(threshold, None, iterations=1) # Aumenta a área do conotorno\n",
    "    '''''\n",
    "    Assim, já com a imagem binária, encontra os contornos e retorna uma lista com todos os contornos,\n",
    "    cada contorno individual é uma matriz Numpy de coordenadas (x, y) de pontos de fronteira do objeto.\n",
    "    '''''\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    time_total = round(time.time() - time_start, 2) # Tempo progredindo no loop\n",
    "    big_moving_things = 0 # Variável para mostrar que está se movendo\n",
    "    \n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour) # Cria caixas delimitadoras e círculos para contornos\n",
    "\n",
    "        if cv2.contourArea(contour) < 500: # Continua o loop para uma áreas pequenas (n encontra contorno)\n",
    "            continue\n",
    "        else:\n",
    "            big_moving_things += 1 \n",
    "            cv2.rectangle(frame1, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "            # Continua o loop, porém muda a variável e marca contornos maiores com um retângulo\n",
    "\n",
    "    if big_moving_things > 0: # Caso encontre contorno, mostra a mensagem \"move\" no video\n",
    "        msg = \"move\"\n",
    "        color = (0, 255, 0)\n",
    "        prev_moving = True\n",
    "    else:\n",
    "        msg = \"n move\" # Caso não encontre contorno, mostra a mensagem \"n move\" no video\n",
    "        color = (0, 0, 255)\n",
    "        if prev_moving: #Caso encontre um contorno no frame anterior (havia movimento)\n",
    "            stops_list.append(time_total) #Tempo em que a oscilação acaba\n",
    "\n",
    "            if len(stops_list) > 1:\n",
    "                T_half = round(time_total - stops_list[-2], 2)\n",
    "                '''''\n",
    "                Se a lista com os tempos que não há oscilação for maior q 1, retira ela do periodo \n",
    "                total para descontar e tem-se a \"metade do periodo\" \n",
    "                '''''\n",
    "            else:\n",
    "                T_half = 0\n",
    "\n",
    "            if T_half >= 0.3:\n",
    "                prev_moving = False\n",
    "                stops_count += 1\n",
    "                T_half_list.append(T)\n",
    "                '''''\n",
    "                Se a lista com os tempos que não há oscilação for maior ou igual a 0.3, considera-se o\n",
    "                último frame como estático e adiciona o periodo à lista de metades do periodo. \n",
    "                '''''\n",
    "\n",
    "            if (stops_count % 2 == 0):\n",
    "                T_timestamp = time.time()\n",
    "                T_timestamps.append(T_timestamp)\n",
    "                '''''\n",
    "                Se a a variável for par, ou seja, se o if anterir ocorrer duas vezes, quatro, seis,\n",
    "                etc, indicando que o pendulo percorreu um periodo inteiro, adiciona o tempo desta \n",
    "                marcação na lista T_timestamp.\n",
    "                '''''\n",
    "                if len(T_timestamps) > 3:\n",
    "                    T = round(T_timestamp - T_timestamps[-2], 2)\n",
    "                    T_list.append(T)\n",
    "                    labels.append(f\"T: {T}\")\n",
    "                    '''''\n",
    "                    Neste último if, caso a soma dos valores da lista sejam maiores q 3 \n",
    "                    (isso para tirar os primeiros periodos q foram grandes demais), adicionamos o\n",
    "                    periodo da oscilação para T_list\n",
    "                    '''''\n",
    "    # Colocar os tempos no video um embaixo do outro\n",
    "    label_y = 60\n",
    "    for label in labels:\n",
    "        label_y += 30\n",
    "        drawText(label, color, (10, label_y))\n",
    "        \n",
    "    # Colocar no video se está se movendo e o tempo total\n",
    "    drawText(msg, color, (10, 40))\n",
    "    drawText(f\"tempo: {time_total}\", color, (120, 40))\n",
    "    \n",
    "    # Colocar no video o g médio e o período médio caso forem medidos\n",
    "    if T_list:\n",
    "        g_avg, _, _ = calc_g()\n",
    "        drawText(f\"g med: {g_avg}\", color, (250, 40))\n",
    "        T_avg, _, _ = calc_T()\n",
    "        drawText(f\"T med: {T_avg}\", color, (430, 40))\n",
    "\n",
    "    \n",
    "    # Mostrar o video\n",
    "    cv2.imshow(\"Movimento pendulo\", frame1)\n",
    "    cv2.imshow(\"Contornos\", blur)\n",
    "    frame1 = frame2\n",
    "    _, frame2 = capture.read()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break #Para quebrar o loop quando apertar o botão 'q'/\n",
    "    if cv2.getWindowProperty('Movimento pendulo', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break #Para quebrar o loop quando fechar a janela\n",
    "    if cv2.getWindowProperty('Contornos', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break #Para quebrar o loop quando fechar a janela\n",
    "\n",
    "# Fim do loop\n",
    "\n",
    "# Para facilitar a visualização, escrever os resultados finais:\n",
    "T_avg, T_min, T_max = calc_T()\n",
    "print(f\"Medido em {len(T_list)} periodos. T medio: {T_avg}, T min: {T_min}, T max: {T_max}\")\n",
    "g_avg, g_min, g_max = calc_g()\n",
    "print(f\"g medio: {g_avg}, g min: {g_min}, g max: {g_max}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be8e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medido em 37 periodos. T medio: 1.38, T min: 0.07, T max: 2.72\n",
      "g medio: 5.18, g min: 1.33, g max: 2012.16\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import cv2\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "length = 0.25\n",
    "\n",
    "capture = cv2.VideoCapture(\"penduloferro.mp4\")\n",
    "fps = round(capture.get(cv2.CAP_PROP_FPS), 2)\n",
    "\n",
    "_, frame1 = capture.read()\n",
    "_, frame2 = capture.read()\n",
    "\n",
    "time_start = time.time()\n",
    "labels = []\n",
    "stops_list = []\n",
    "T_list = []\n",
    "T_half_list = []\n",
    "T_timestamps = []\n",
    "\n",
    "\n",
    "def calc_T() -> Tuple[float, float, float]:\n",
    "    avg = round(numpy.mean(T_list), 2)\n",
    "    low = round(numpy.min(T_list), 2)\n",
    "    high = round(numpy.max(T_list), 2)\n",
    "    return (avg, low, high)\n",
    "\n",
    "\n",
    "def calc_g() -> Tuple[float, float, float]:\n",
    "    T_avg, T_min, T_max = calc_T()\n",
    "    g_avg = (4 * 3.14 * 3.14 * length) / (T_avg**2)\n",
    "    g_min = (4 * 3.14 * 3.14 * length) / (T_max**2)\n",
    "    g_max = (4 * 3.14 * 3.14 * length) / (T_min**2)\n",
    "\n",
    "    return (round(g_avg, 2), round(g_min, 2), round(g_max, 2))\n",
    "\n",
    "\n",
    "def drawText(text: str,\n",
    "             color: Tuple[int, int, int],\n",
    "             pos: Tuple[int, int],\n",
    "             big=False,\n",
    "             console=False):\n",
    "    if console:\n",
    "        print(text)\n",
    "\n",
    "    if big:\n",
    "        scale = 1\n",
    "        thickness = 4\n",
    "    else:\n",
    "        scale = 0.6\n",
    "        thickness = 2\n",
    "\n",
    "    cv2.putText(frame1, str(text), org=pos, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=scale, color=color, thickness=3)\n",
    "\n",
    "\n",
    "prev_moving = False\n",
    "stops_count = 0\n",
    "while capture.isOpened() and frame1 is not None and frame2 is not None:\n",
    "    t0 = cv2.getTickCount()\n",
    "    T = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(T, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, threshold = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(threshold, None, iterations=1)\n",
    "    contours, _ = cv2.findContours(\n",
    "        dilated, cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    time_total = round(time.time() - time_start, 2)\n",
    "    big_moving_things = 0\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 400:\n",
    "            continue\n",
    "        else:\n",
    "            big_moving_things += 1\n",
    "            cv2.rectangle(frame1, pt1=(x, y), pt2=(x + w, y + h),\n",
    "                          color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    if big_moving_things > 0:\n",
    "        msg = \"move\"\n",
    "        color = (0, 255, 0)\n",
    "        prev_moving = True\n",
    "    else:\n",
    "        msg = \"n move\"\n",
    "        color = (0, 0, 255)\n",
    "        if prev_moving:\n",
    "            stops_list.append(time_total)\n",
    "\n",
    "            if len(stops_list) > 1:\n",
    "                T_half = round(time_total - stops_list[-2], 2)\n",
    "            else:\n",
    "                T_half = 0\n",
    "\n",
    "            if T_half >= 0.3:\n",
    "                prev_moving = False\n",
    "                stops_count += 1\n",
    "                T_half_list.append(T)\n",
    "\n",
    "            if (stops_count % 2 == 0):\n",
    "                T_timestamp = time.time()\n",
    "                T_timestamps.append(T_timestamp)\n",
    "                if len(T_timestamps) > 4:\n",
    "                    T = round(T_timestamp - T_timestamps[-2], 2)\n",
    "                    T_list.append(T)\n",
    "                    labels.append(\n",
    "                        f\"T: {T}\")\n",
    "\n",
    "    label_y = 60\n",
    "    for label in labels:\n",
    "\n",
    "        label_y += 30\n",
    "        drawText(label, color, (10, label_y))\n",
    "\n",
    "    drawText(msg, color, (10, 40))\n",
    "    drawText(f\"total: {time_total}\", color, (120, 40))\n",
    "\n",
    "    if T_list:\n",
    "        g_avg, _, _ = calc_g()\n",
    "        drawText(f\"g med: {g_avg}\", color, (250, 40))\n",
    "\n",
    "        T_avg, _, _ = calc_T()\n",
    "        drawText(f\"T med: {T_avg}\", color, (390, 40))\n",
    "\n",
    "        #print(f\"g avg: {g_avg}, T avg: {T_avg}, stops count: {stops_count}\")\n",
    "\n",
    "    t1 = cv2.getTickCount()\n",
    "    processing_time = round((t1-t0)/cv2.getTickFrequency(), 3)\n",
    "    #print(f\"processing took {processing_time} seconds.\")\n",
    "\n",
    "    cv2.imshow(\"Movimento pendulo\", frame1)\n",
    "    frame1 = frame2\n",
    "    _, frame2 = capture.read()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "T_avg, T_min, T_max = calc_T()\n",
    "print(f\"Medido em {len(T_list)} periodos. T medio: {T_avg}, T min: {T_min}, T max: {T_max}\")\n",
    "g_avg, g_min, g_max = calc_g()\n",
    "print(f\"g medio: {g_avg}, g min: {g_min}, g max: {g_max}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42006ad",
   "metadata": {},
   "source": [
    "Neste caso foi aumentado o número no \"if len(T_timestamps) > 4:\" pois os primeiros periodos estavam muito grandes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
